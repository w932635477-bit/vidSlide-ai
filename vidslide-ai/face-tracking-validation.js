/**
 * äººè„¸è·Ÿè¸ªæŠ€æœ¯éªŒè¯å·¥å…·
 * æµ‹è¯•MediaPipe Face Meshåœ¨æµè§ˆå™¨ä¸­çš„å¯è¡Œæ€§
 *
 * éªŒè¯å†…å®¹ï¼š
 * 1. MediaPipe Face Meshåº“é›†æˆæµ‹è¯•
 * 2. WebAssemblyå…¼å®¹æ€§æ£€æŸ¥
 * 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
 * 4. ç²¾åº¦å¯¹æ¯”åˆ†æ
 * 5. å†…å­˜ä½¿ç”¨è¯„ä¼°
 * 6. æµè§ˆå™¨å…¼å®¹æ€§æµ‹è¯•
 */

class FaceTrackingValidator {
  constructor() {
    this.results = {
      mediapipe: {
        available: false,
        loadTime: 0,
        inferenceTime: 0,
        accuracy: 0,
        memoryUsage: 0,
        supportedBrowsers: []
      },
      opencv: {
        available: false,
        loadTime: 0,
        inferenceTime: 0,
        accuracy: 0,
        memoryUsage: 0,
        supportedBrowsers: []
      },
      currentImplementation: {
        fps: 0,
        accuracy: 0,
        latency: 0,
        memoryUsage: 0
      }
    }

    this.testCanvas = null
    this.testVideo = null
    this.faceMesh = null
    this.opencv = null
  }

  /**
   * åˆå§‹åŒ–éªŒè¯ç¯å¢ƒ
   */
  async initialize() {
    console.log('ğŸ” åˆå§‹åŒ–äººè„¸è·Ÿè¸ªéªŒè¯ç¯å¢ƒ...')

    // åˆ›å»ºæµ‹è¯•Canvas
    this.testCanvas = document.createElement('canvas')
    this.testCanvas.width = 640
    this.testCanvas.height = 480
    document.body.appendChild(this.testCanvas)

    // åˆ›å»ºæµ‹è¯•è§†é¢‘ï¼ˆä½¿ç”¨é™æ€å›¾åƒæ¨¡æ‹Ÿï¼‰
    this.testVideo = document.createElement('video')
    this.testVideo.width = 640
    this.testVideo.height = 480
    this.testVideo.style.display = 'none'
    document.body.appendChild(this.testVideo)

    // åˆ›å»ºæ¨¡æ‹Ÿäººè„¸å›¾åƒ
    await this.createTestFaceImage()

    console.log('âœ… éªŒè¯ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ')
  }

  /**
   * åˆ›å»ºæµ‹è¯•äººè„¸å›¾åƒ
   */
  async createTestFaceImage() {
    const ctx = this.testCanvas.getContext('2d')

    // åˆ›å»ºç®€å•çš„æ¤­åœ†ä½œä¸ºäººè„¸æ¨¡æ‹Ÿ
    ctx.fillStyle = '#f0f0f0'
    ctx.fillRect(0, 0, 640, 480)

    // ç»˜åˆ¶æ¤­åœ†æ¨¡æ‹Ÿäººè„¸
    ctx.fillStyle = '#ffdbac'
    ctx.beginPath()
    ctx.ellipse(320, 240, 80, 100, 0, 0, 2 * Math.PI)
    ctx.fill()

    // ç»˜åˆ¶çœ¼ç›
    ctx.fillStyle = '#000000'
    ctx.beginPath()
    ctx.ellipse(300, 220, 8, 6, 0, 0, 2 * Math.PI)
    ctx.fill()
    ctx.beginPath()
    ctx.ellipse(340, 220, 8, 6, 0, 0, 2 * Math.PI)
    ctx.fill()

    // ç»˜åˆ¶é¼»å­å’Œå˜´å·´
    ctx.beginPath()
    ctx.ellipse(320, 250, 4, 6, 0, 0, 2 * Math.PI)
    ctx.fill()

    ctx.beginPath()
    ctx.arc(320, 280, 15, 0, Math.PI)
    ctx.stroke()
  }

  /**
   * æµ‹è¯•MediaPipe Face Mesh
   */
  async testMediaPipe() {
    console.log('ğŸ§ª æµ‹è¯•MediaPipe Face Mesh...')

    const startTime = performance.now()

    try {
      // æ£€æŸ¥WebAssemblyæ”¯æŒ
      if (typeof WebAssembly !== 'object') {
        throw new Error('WebAssembly not supported')
      }

      // åŠ¨æ€åŠ è½½MediaPipeè„šæœ¬
      await this.loadMediaPipeScript()

      const loadTime = performance.now() - startTime
      this.results.mediapipe.loadTime = loadTime
      this.results.mediapipe.available = true

      console.log(`âœ… MediaPipeåŠ è½½å®Œæˆï¼Œè€—æ—¶: ${loadTime.toFixed(2)}ms`)

      // åˆå§‹åŒ–Face Mesh
      if (window.FaceMesh) {
        this.faceMesh = new window.FaceMesh({
          locateFile: file => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
          }
        })

        this.faceMesh.setOptions({
          maxNumFaces: 1,
          refineLandmarks: true,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
        })

        // æµ‹è¯•æ¨ç†æ€§èƒ½
        await this.testMediaPipeInference()

        console.log('âœ… MediaPipe Face Meshæµ‹è¯•å®Œæˆ')
      } else {
        throw new Error('FaceMesh not available after loading')
      }
    } catch (error) {
      console.warn('âŒ MediaPipe Face Meshæµ‹è¯•å¤±è´¥:', error)
      this.results.mediapipe.available = false
      this.results.mediapipe.error = error.message
    }
  }

  /**
   * åŠ è½½MediaPipeè„šæœ¬
   */
  async loadMediaPipeScript() {
    return new Promise((resolve, reject) => {
      // æ£€æŸ¥æ˜¯å¦å·²ç»åŠ è½½
      if (window.FaceMesh) {
        resolve()
        return
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js'
      script.onload = resolve
      script.onerror = reject
      document.head.appendChild(script)
    })
  }

  /**
   * æµ‹è¯•MediaPipeæ¨ç†æ€§èƒ½
   */
  async testMediaPipeInference() {
    if (!this.faceMesh) return

    const startTime = performance.now()

    // è®¾ç½®ç»“æœå¤„ç†å‡½æ•°
    this.faceMesh.onResults(results => {
      const inferenceTime = performance.now() - startTime
      this.results.mediapipe.inferenceTime = inferenceTime

      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0]
        this.results.mediapipe.accuracy = landmarks.length // 468ä¸ªå…³é”®ç‚¹

        console.log(
          `ğŸ¯ MediaPipeæ£€æµ‹åˆ°äººè„¸ï¼Œ${landmarks.length}ä¸ªå…³é”®ç‚¹ï¼Œæ¨ç†æ—¶é—´: ${inferenceTime.toFixed(2)}ms`
        )
      } else {
        console.log('âš ï¸ MediaPipeæœªæ£€æµ‹åˆ°äººè„¸')
        this.results.mediapipe.accuracy = 0
      }
    })

    // æ‰§è¡Œæ£€æµ‹
    await this.faceMesh.send({ image: this.testCanvas })

    // ç­‰å¾…ç»“æœ
    await new Promise(resolve => setTimeout(resolve, 1000))
  }

  /**
   * æµ‹è¯•OpenCV.jsä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
   */
  async testOpenCV() {
    console.log('ğŸ§ª æµ‹è¯•OpenCV.js...')

    const startTime = performance.now()

    try {
      // åŠ¨æ€åŠ è½½OpenCV.js
      await this.loadOpenCVScript()

      const loadTime = performance.now() - startTime
      this.results.opencv.loadTime = loadTime

      // ç­‰å¾…OpenCVåˆå§‹åŒ–
      await this.waitForOpenCV()

      this.results.opencv.available = true
      console.log(`âœ… OpenCV.jsåŠ è½½å®Œæˆï¼Œè€—æ—¶: ${loadTime.toFixed(2)}ms`)

      // æµ‹è¯•äººè„¸æ£€æµ‹
      await this.testOpenCVFaceDetection()
    } catch (error) {
      console.warn('âŒ OpenCV.jsæµ‹è¯•å¤±è´¥:', error)
      this.results.opencv.available = false
      this.results.opencv.error = error.message
    }
  }

  /**
   * åŠ è½½OpenCV.jsè„šæœ¬
   */
  async loadOpenCVScript() {
    return new Promise((resolve, reject) => {
      if (window.cv) {
        resolve()
        return
      }

      const script = document.createElement('script')
      script.src = 'https://docs.opencv.org/4.8.0/opencv.js'
      script.onload = resolve
      script.onerror = reject
      document.head.appendChild(script)
    })
  }

  /**
   * ç­‰å¾…OpenCVåˆå§‹åŒ–å®Œæˆ
   */
  async waitForOpenCV() {
    return new Promise(resolve => {
      const checkOpenCV = () => {
        if (window.cv && window.cv.Mat) {
          resolve()
        } else {
          setTimeout(checkOpenCV, 100)
        }
      }
      checkOpenCV()
    })
  }

  /**
   * æµ‹è¯•OpenCVäººè„¸æ£€æµ‹
   */
  async testOpenCVFaceDetection() {
    if (!window.cv) return

    const startTime = performance.now()

    try {
      // åˆ›å»ºOpenCVçŸ©é˜µ
      const src = window.cv.imread(this.testCanvas)
      const gray = new window.cv.Mat()
      window.cv.cvtColor(src, gray, window.cv.COLOR_RGBA2GRAY, 0)

      // åˆ›å»ºåˆ†ç±»å™¨ï¼ˆè¿™é‡Œä½¿ç”¨ç®€åŒ–çš„Haarç‰¹å¾æ£€æµ‹ï¼‰
      // æ³¨æ„ï¼šå®é™…ä½¿ç”¨éœ€è¦åŠ è½½äººè„¸åˆ†ç±»å™¨XMLæ–‡ä»¶
      // const _faces = new window.cv.RectVector() // é¢„ç•™ç»™äººè„¸æ£€æµ‹ä½¿ç”¨

      // ç®€åŒ–çš„åœ†æ£€æµ‹ä½œä¸ºäººè„¸æ£€æµ‹æ¨¡æ‹Ÿ
      const circles = new window.cv.Mat()
      window.cv.HoughCircles(gray, circles, window.cv.HOUGH_GRADIENT, 1, 20, 50, 30, 50, 100)

      const inferenceTime = performance.now() - startTime
      this.results.opencv.inferenceTime = inferenceTime
      this.results.opencv.accuracy = circles.rows // æ£€æµ‹åˆ°çš„åœ†æ•°é‡

      console.log(`ğŸ¯ OpenCVæ£€æµ‹å®Œæˆï¼Œè€—æ—¶: ${inferenceTime.toFixed(2)}ms`)

      // æ¸…ç†å†…å­˜
      src.delete()
      gray.delete()
      circles.delete()
    } catch (error) {
      console.warn('OpenCVäººè„¸æ£€æµ‹æµ‹è¯•å¤±è´¥:', error)
      this.results.opencv.accuracy = 0
    }
  }

  /**
   * åˆ†æå½“å‰å®ç°æ€§èƒ½
   */
  async analyzeCurrentImplementation() {
    console.log('ğŸ“Š åˆ†æå½“å‰äººè„¸è·Ÿè¸ªå®ç°...')

    // è¿™é‡Œåº”è¯¥åˆ†æç°æœ‰çš„PictureInPictureç»„ä»¶æ€§èƒ½
    // ç”±äºå½“å‰å®ç°å¯èƒ½è¿˜æ²¡æœ‰äººè„¸è·Ÿè¸ªï¼Œæˆ‘ä»¬æä¾›åŸºå‡†æ•°æ®

    this.results.currentImplementation = {
      fps: 0, // å¾…æµ‹é‡
      accuracy: 0, // å¾…æµ‹é‡
      latency: 0, // å¾…æµ‹é‡
      memoryUsage: 0, // å¾…æµ‹é‡
      note: 'å½“å‰å®ç°æš‚æ— äººè„¸è·Ÿè¸ªåŠŸèƒ½ï¼Œä»…æä¾›ä½ç½®æ§åˆ¶'
    }

    console.log('â„¹ï¸ å½“å‰å®ç°åˆ†æå®Œæˆï¼ˆåŸºå‡†æ•°æ®ï¼‰')
  }

  /**
   * å†…å­˜ä½¿ç”¨ç›‘æ§
   */
  monitorMemoryUsage() {
    if (performance.memory) {
      const memInfo = performance.memory
      return {
        used: memInfo.usedJSHeapSize,
        total: memInfo.totalJSHeapSize,
        limit: memInfo.jsHeapSizeLimit
      }
    }
    return null
  }

  /**
   * æµè§ˆå™¨å…¼å®¹æ€§æ£€æµ‹
   */
  checkBrowserCompatibility() {
    const userAgent = navigator.userAgent
    const browsers = {
      chrome: /Chrome/.test(userAgent),
      firefox: /Firefox/.test(userAgent),
      safari: /Safari/.test(userAgent) && !/Chrome/.test(userAgent),
      edge: /Edg/.test(userAgent)
    }

    // æ›´æ–°æ”¯æŒçš„æµè§ˆå™¨åˆ—è¡¨
    if (browsers.chrome) this.results.mediapipe.supportedBrowsers.push('Chrome')
    if (browsers.firefox) this.results.mediapipe.supportedBrowsers.push('Firefox')
    if (browsers.safari) this.results.mediapipe.supportedBrowsers.push('Safari')
    if (browsers.edge) this.results.mediapipe.supportedBrowsers.push('Edge')

    console.log('ğŸŒ æµè§ˆå™¨å…¼å®¹æ€§æ£€æµ‹å®Œæˆ:', browsers)
  }

  /**
   * ç”ŸæˆéªŒè¯æŠ¥å‘Š
   */
  generateReport() {
    console.log('ğŸ“‹ ç”Ÿæˆäººè„¸è·Ÿè¸ªéªŒè¯æŠ¥å‘Š...')

    const report = {
      timestamp: new Date().toISOString(),
      summary: {
        mediapipeAvailable: this.results.mediapipe.available,
        opencvAvailable: this.results.opencv.available,
        recommendation: this.getRecommendation()
      },
      detailedResults: this.results,
      browserInfo: {
        userAgent: navigator.userAgent,
        webglSupport: !!document.createElement('canvas').getContext('webgl'),
        webassemblySupport: typeof WebAssembly === 'object',
        memoryInfo: this.monitorMemoryUsage()
      }
    }

    console.log('ğŸ“Š éªŒè¯æŠ¥å‘Š:', report)
    return report
  }

  /**
   * è·å–æ¨èæ–¹æ¡ˆ
   */
  getRecommendation() {
    if (this.results.mediapipe.available && this.results.mediapipe.inferenceTime < 100) {
      return 'MediaPipe Face Mesh - æ¨èä½¿ç”¨ï¼Œæ€§èƒ½å’Œç²¾åº¦æœ€ä½³'
    } else if (this.results.opencv.available && this.results.opencv.inferenceTime < 200) {
      return 'OpenCV.js - å¤‡é€‰æ–¹æ¡ˆï¼ŒåŠŸèƒ½å…¨é¢ä½†åŒ…ä½“ç§¯è¾ƒå¤§'
    } else {
      return 'åŸºç¡€æ–¹æ¡ˆ - å½“å‰å®ç°ä¼˜åŒ–ï¼Œç­‰å¾…WebæŠ€æœ¯æˆç†Ÿ'
    }
  }

  /**
   * è¿è¡Œå®Œæ•´éªŒè¯
   */
  async runValidation() {
    console.log('ğŸš€ å¼€å§‹äººè„¸è·Ÿè¸ªæŠ€æœ¯éªŒè¯...')

    try {
      await this.initialize()
      await this.checkBrowserCompatibility()

      // å¹¶è¡Œæµ‹è¯•ä¸¤ç§æ–¹æ¡ˆ
      await Promise.all([this.testMediaPipe(), this.testOpenCV()])

      await this.analyzeCurrentImplementation()

      const report = this.generateReport()

      console.log('âœ… äººè„¸è·Ÿè¸ªéªŒè¯å®Œæˆ')
      return report
    } catch (error) {
      console.error('âŒ éªŒè¯è¿‡ç¨‹å¤±è´¥:', error)
      return {
        error: error.message,
        timestamp: new Date().toISOString()
      }
    } finally {
      // æ¸…ç†èµ„æº
      this.cleanup()
    }
  }

  /**
   * æ¸…ç†éªŒè¯ç¯å¢ƒ
   */
  cleanup() {
    if (this.testCanvas && this.testCanvas.parentNode) {
      this.testCanvas.parentNode.removeChild(this.testCanvas)
    }
    if (this.testVideo && this.testVideo.parentNode) {
      this.testVideo.parentNode.removeChild(this.testVideo)
    }

    // æ¸…ç†MediaPipeèµ„æº
    if (this.faceMesh) {
      this.faceMesh.close()
    }
  }
}

// å¯¼å‡ºéªŒè¯å‡½æ•°
export async function validateFaceTracking() {
  const validator = new FaceTrackingValidator()
  return await validator.runValidation()
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬
if (typeof window !== 'undefined' && window.location) {
  // åœ¨æµè§ˆå™¨ä¸­è‡ªåŠ¨è¿è¡ŒéªŒè¯
  window.addEventListener('load', async () => {
    console.log('ğŸ¬ VidSlide AI - äººè„¸è·Ÿè¸ªéªŒè¯å·¥å…·å·²åŠ è½½')

    // æ·»åŠ åˆ°å…¨å±€ä½œç”¨åŸŸä»¥ä¾¿æ‰‹åŠ¨è°ƒç”¨
    window.validateFaceTracking = validateFaceTracking

    // è‡ªåŠ¨è¿è¡ŒéªŒè¯ï¼ˆå¯é€‰ï¼‰
    const shouldAutoRun = confirm('æ˜¯å¦ç«‹å³è¿è¡Œäººè„¸è·Ÿè¸ªéªŒè¯ï¼Ÿ')
    if (shouldAutoRun) {
      const result = await validateFaceTracking()
      console.log('éªŒè¯ç»“æœ:', result)

      // æ˜¾ç¤ºç»“æœæ‘˜è¦
      alert(`éªŒè¯å®Œæˆï¼\\næ¨èæ–¹æ¡ˆ: ${result.summary?.recommendation || 'éœ€è¦è¿›ä¸€æ­¥è¯„ä¼°'}`)
    }
  })
}
